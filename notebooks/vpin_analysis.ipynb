{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic VPIN Implementation Using Rust Module\n",
    "\n",
    "Volume-Synchronized Probability of Informed Trading (VPIN) analysis using academic methodology from Easley, López de Prado, O'Hara (2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import rust_indicators\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ta = rust_indicators.RustTA()\n",
    "cg = CoinGeckoAPI()\n",
    "coin = 'ethereum'\n",
    "days = 180\n",
    "print(f\"✓ Backend: {ta.device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Academic VPIN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_volume_buckets(df, bucket_size_pct=0.01):\n",
    "    \"\"\"\n",
    "    Create volume-synchronized buckets as per academic VPIN\n",
    "    Each bucket contains exactly V volume units\n",
    "    \"\"\"\n",
    "    # Calculate bucket size as percentage of average daily volume\n",
    "    n_days = df['datetime'].dt.normalize().nunique()\n",
    "    avg_daily_volume = df['volume'].sum() / max(1, n_days)\n",
    "    bucket_size = avg_daily_volume * bucket_size_pct\n",
    "    \n",
    "    # Create volume buckets\n",
    "    df['cum_volume'] = df['volume'].cumsum()\n",
    "    df['bucket_id'] = (df['cum_volume'] / bucket_size).astype(int)\n",
    "    \n",
    "    # Aggregate to bucket level\n",
    "    buckets = df.groupby('bucket_id').agg({\n",
    "        'datetime': 'first',\n",
    "        'price': ['first', 'last'],\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "    \n",
    "    buckets.columns = ['datetime', 'open', 'close', 'volume']\n",
    "    buckets['price_change'] = buckets['close'] - buckets['open']\n",
    "    buckets = buckets.reset_index()\n",
    "    \n",
    "    return buckets, bucket_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_volume_classification(buckets, window=50):\n",
    "    \"\"\"\n",
    "    Implement Bulk Volume Classification (BVC) algorithm\n",
    "    from Easley, López de Prado, O'Hara (2012)\n",
    "    \"\"\"\n",
    "\n",
    "    buckets['ret'] = np.log(buckets['close']).diff().fillna(0.0)\n",
    "    buckets['sigma'] = buckets['ret'].rolling(window, min_periods=10).std()\n",
    "    buckets['sigma'] = buckets['sigma'].fillna(method='bfill')\n",
    "    buckets['sigma'] = buckets['sigma'].replace(0, np.nan).fillna(buckets['ret'].std())\n",
    "    sigma_floor = 1e-6\n",
    "    buckets['z_score'] = buckets['ret'] / (buckets['sigma'].clip(lower=sigma_floor))\n",
    "    buckets['buy_prob'] = norm.cdf(buckets['z_score'])\n",
    "    buckets['buy_volume']  = buckets['volume'] * buckets['buy_prob']\n",
    "    buckets['sell_volume'] = buckets['volume'] * (1 - buckets['buy_prob'])\n",
    "\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_academic_vpin(df, bucket_size_pct=0.01, vpin_window=50):\n",
    "    \"\"\"\n",
    "    Calculate VPIN using academic methodology with Rust module\n",
    "    \"\"\"\n",
    "    # Step 1: Create volume buckets\n",
    "    buckets, bucket_size = create_volume_buckets(df, bucket_size_pct)\n",
    "    \n",
    "    # Step 2: Apply Bulk Volume Classification\n",
    "    buckets = bulk_volume_classification(buckets, window=vpin_window)\n",
    "    # after creating `buckets`\n",
    "\n",
    "\n",
    "    if len(buckets) <= 2:\n",
    "        raise ValueError(\"Too few buckets. Reduce bucket_size_pct.\")\n",
    "    if vpin_window >= len(buckets):\n",
    "        vpin_window = max(2, int(0.2 * len(buckets)))  # e.g., 20% of buckets\n",
    "\n",
    "    # Step 3: Calculate VPIN using Rust module on bucketed data\n",
    "    vpin_values = np.array(ta.vpin(\n",
    "        buckets['buy_volume'].values,\n",
    "        buckets['sell_volume'].values,\n",
    "        vpin_window\n",
    "    ))\n",
    "    \n",
    "    buckets['vpin'] = vpin_values\n",
    "    \n",
    "    # Step 4: Map back to original timeframe\n",
    "    df['bucket_id'] = (df['volume'].cumsum() / bucket_size).astype(int)\n",
    "    vpin_map = dict(zip(buckets['bucket_id'], vpin_values))\n",
    "    df['vpin'] = df['bucket_id'].map(vpin_map)\n",
    "    \n",
    "    return df, buckets, vpin_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "def calculate_vpin_cdf(vpin_values):\n",
    "    out = np.full_like(vpin_values, np.nan, dtype=float)\n",
    "    m = ~np.isnan(vpin_values)\n",
    "    if m.sum() == 0:\n",
    "        return out\n",
    "    ranks = rankdata(vpin_values[m], method='average')  # 1..N\n",
    "    out[m] = ranks / (len(ranks) + 1.0)                 # (0,1)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and VPIN Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch real data\n",
    "print(\"Fetching Bitcoin data...\")\n",
    "data = cg.get_coin_market_chart_by_id(coin, vs_currency='usd', days=days)\n",
    "\n",
    "df = pd.DataFrame(data['prices'], columns=['timestamp', 'price'])\n",
    "df['volume'] = pd.DataFrame(data['total_volumes'])[1]\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(f\"Data: {len(df)} points from {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "\n",
    "# Calculate academic VPIN\n",
    "print(\"\\nCalculating academic VPIN...\")\n",
    "df, buckets, vpin_raw = calculate_academic_vpin(df, bucket_size_pct=0.01)\n",
    "\n",
    "# Convert to CDF (toxicity metric)\n",
    "vpin_cdf = calculate_vpin_cdf(vpin_raw)\n",
    "buckets['vpin_cdf'] = vpin_cdf\n",
    "\n",
    "# Identify toxicity events\n",
    "buckets['toxic_event'] = vpin_cdf > 0.9\n",
    "\n",
    "print(f\"Buckets: {len(buckets)} volume-synchronized buckets\")\n",
    "print(f\"Toxic events: {buckets['toxic_event'].sum()} buckets with CDF > 0.9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Academic VPIN Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_academic_vpin(df, buckets, vpin_raw):\n",
    "    \"\"\"\n",
    "    Create academic VPIN visualization with toxicity levels\n",
    "    \"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=4, cols=1,\n",
    "        row_heights=[0.25, 0.25, 0.25, 0.25],\n",
    "        subplot_titles=[\n",
    "            'Price with Volume Buckets',\n",
    "            'Order Flow Imbalance (Buy vs Sell Volume)',\n",
    "            'VPIN (Raw) - Order Flow Toxicity',\n",
    "            'VPIN CDF - Toxicity Probability'\n",
    "        ],\n",
    "        vertical_spacing=0.05\n",
    "    )\n",
    "    \n",
    "    # 1. Price with bucket boundaries\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['datetime'],\n",
    "            y=df['price'],\n",
    "            name='Price',\n",
    "            line=dict(color='lightblue', width=1)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Mark every 10th bucket boundary\n",
    "    bucket_starts = df.groupby('bucket_id')['datetime'].first()\n",
    "    for i, start_time in enumerate(bucket_starts):\n",
    "        if i % 10 == 0:\n",
    "            fig.add_vline(x=start_time, line_dash=\"dot\", \n",
    "                         line_color=\"gray\", opacity=0.3, row=1, col=1)\n",
    "    \n",
    "    # 2. Order Flow Imbalance\n",
    "    imbalance = buckets['buy_volume'] - buckets['sell_volume']\n",
    "    colors = ['green' if x > 0 else 'red' for x in imbalance]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=buckets['datetime'],\n",
    "            y=imbalance,\n",
    "            marker_color=colors,\n",
    "            opacity=0.6,\n",
    "            name='Volume Imbalance',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 3. Raw VPIN\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=buckets['datetime'],\n",
    "            y=vpin_raw,\n",
    "            name='VPIN',\n",
    "            line=dict(color='orange', width=2)\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # Add Flash Crash threshold\n",
    "    fig.add_hline(y=0.2, line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=\"Flash Crash Level (0.2)\",\n",
    "                  row=3, col=1)\n",
    "    \n",
    "    # 4. VPIN CDF\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=buckets['datetime'],\n",
    "            y=buckets['vpin_cdf'],\n",
    "            name='Toxicity Probability',\n",
    "            fill='tozeroy',\n",
    "            line=dict(color='purple', width=2)\n",
    "        ),\n",
    "        row=4, col=1\n",
    "    )\n",
    "    \n",
    "    # Mark extreme toxicity events\n",
    "    toxic_events = buckets[buckets['toxic_event']]\n",
    "    if len(toxic_events) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=toxic_events['datetime'],\n",
    "                y=toxic_events['vpin_cdf'],\n",
    "                mode='markers',\n",
    "                marker=dict(color='red', size=10, symbol='x'),\n",
    "                name='Toxic Events',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=4, col=1\n",
    "        )\n",
    "    \n",
    "    # Add 90% threshold\n",
    "    fig.add_hline(y=0.9, line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=\"Extreme Toxicity (90%)\",\n",
    "                  row=4, col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        title=\"Academic VPIN: Volume-Synchronized Order Flow Toxicity\",\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=True,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title=\"Price ($)\", row=1, col=1)\n",
    "    fig.update_yaxes(title=\"Volume Δ\", row=2, col=1)\n",
    "    fig.update_yaxes(title=\"VPIN\", row=3, col=1)\n",
    "    fig.update_yaxes(title=\"CDF\", range=[0, 1], row=4, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_academic_vpin(df, buckets, vpin_raw)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Metrics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_toxicity_metrics(buckets, vpin_raw):\n",
    "    \"\"\"\n",
    "    Calculate key metrics from academic VPIN papers\n",
    "    \"\"\"\n",
    "    # Clean data\n",
    "    clean_vpin = vpin_raw[~np.isnan(vpin_raw)]\n",
    "    \n",
    "    if len(clean_vpin) == 0:\n",
    "        print(\"No valid VPIN values to analyze\")\n",
    "        return None\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        'mean_vpin': np.mean(clean_vpin),\n",
    "        'std_vpin': np.std(clean_vpin),\n",
    "        'max_vpin': np.max(clean_vpin),\n",
    "        'toxic_periods': (buckets['vpin_cdf'] > 0.9).sum(),\n",
    "        'total_buckets': len(buckets),\n",
    "        'avg_bucket_imbalance': np.mean(np.abs(\n",
    "            buckets['buy_volume'] - buckets['sell_volume']\n",
    "        ) / (buckets['volume'] + 1e-10))\n",
    "    }\n",
    "    \n",
    "    # Print Flash Crash-style analysis\n",
    "    print(\"=\"*60)\n",
    "    print(\"ACADEMIC VPIN ANALYSIS (Easley et al. 2012 Methodology)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"📊 Mean VPIN: {metrics['mean_vpin']:.4f}\")\n",
    "    print(f\"📈 Max VPIN: {metrics['max_vpin']:.4f}\")\n",
    "    print(f\"⚠️  Toxic Events (CDF>0.9): {metrics['toxic_periods']}/{metrics['total_buckets']} buckets\")\n",
    "    print(f\"📉 Avg Order Imbalance: {metrics['avg_bucket_imbalance']:.2%}\")\n",
    "    \n",
    "    # Warning levels\n",
    "    if metrics['max_vpin'] > 0.2:\n",
    "        print(\"🚨 WARNING: VPIN exceeds Flash Crash threshold (0.2)\")\n",
    "    \n",
    "    toxicity_pct = metrics['toxic_periods'] / metrics['total_buckets'] * 100\n",
    "    if toxicity_pct > 5:\n",
    "        print(f\"🚨 HIGH TOXICITY: {toxicity_pct:.1f}% of time in toxic state\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "metrics = calculate_toxicity_metrics(buckets, vpin_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Time-based vs Volume-based VPIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple time-based VPIN for comparison\n",
    "print(\"\\nCalculating time-based VPIN for comparison...\")\n",
    "time_vpin = np.array(ta.vpin(\n",
    "    df['volume'].values * 0.5,  # Simple 50/50 split\n",
    "    df['volume'].values * 0.5,\n",
    "    50\n",
    "))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Time-based vs Volume-bucket VPIN Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Time-based max: {np.nanmax(time_vpin):.4f}\")\n",
    "print(f\"Volume-bucket max: {metrics['max_vpin']:.4f}\")\n",
    "print(f\"Difference: {abs(metrics['max_vpin'] - np.nanmax(time_vpin)):.4f}\")\n",
    "print(f\"\\nVolume-bucket approach is {'higher' if metrics['max_vpin'] > np.nanmax(time_vpin) else 'lower'}\")\n",
    "print(\"This difference reflects the impact of volume synchronization\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Academic Features Implemented:\n",
    "\n",
    "1. **Volume Bucket Synchronization**: Each bucket contains exactly V volume units (1% of daily volume)\n",
    "2. **Bulk Volume Classification (BVC)**: Uses CDF of normalized price changes to classify volume\n",
    "3. **CDF Transformation**: Converts VPIN to toxicity probability (0-1 scale)\n",
    "4. **Flash Crash Thresholds**: Uses 0.2 raw VPIN and 0.9 CDF as critical levels\n",
    "5. **Order Flow Imbalance**: Direct visualization of buy-sell pressure per bucket\n",
    "\n",
    "### References:\n",
    "- Easley, López de Prado, O'Hara (2012) \"Flow Toxicity and Liquidity in a High-frequency World\"\n",
    "- López de Prado (2018) \"Advances in Financial Machine Learning\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
